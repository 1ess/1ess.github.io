<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author"><title> · A Sort Of A Blog</title><meta name="description" content="接下来的几篇，我们将介绍一下最流行的爬虫框架 Scrapy。本篇，我们会介绍一下 Scrapy 的基本使用。
基本命令
1234567891011121314# scrapy startproject [文件夹名]scrapy startproject quotetutorial# 进入项目文件夹c"><meta name="keywords" content=""><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="https://cdn.jsdelivr.net/gh/1ess/cdn/h4cker/favicon-32x32.png" type="image/x-icon"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/style.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><meta name="generator" content="Hexo 5.4.0"><link rel="stylesheet" href="/css/prism.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div id="stage" class="container"><div class="row"><div id="side-bar" class="col-sm-3 col-xs-12 side-container invisible"><div class="vertical-text site-title"><h3 tabindex="-1" class="site-title-small"><a href="/" class="a-title">0x7c00</a></h3><h1 tabindex="-1" class="site-title-large"><a href="/" class="a-title">张冬冬的博客</a></h1><!--h6(onclick="triggerSiteNav()") Trigger--></div><br class="visible-lg visible-md visible-sm"><div id="site-nav" class="site-title-links"><ul><li><a href="/">首頁</a></li><li><a href="/archives">歸檔</a></li><li class="soc"><a href="https://github.com/1ess" target="_blank" rel="noopener noreferrer"><i class="fa fa-github">&nbsp;</i></a></li></ul><div class="visible-lg visible-md visible-sm site-nav-footer"><br class="site-nav-footer-br"><footer><p>&copy;&nbsp;2021&nbsp;</p><p>如果五分钟后她必须进安检，如果安检在十米之外</p><p>那意味着，你们可以亲吻四分五十秒。&nbsp;</p></footer></div></div></div><div id="main-container" class="col-sm-9 col-xs-12 main-container invisible"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post-container"><p class="post-title"><a></a></p><p class="post-meta"><span class="date meta-item">發佈於&nbsp;2021-07-14</span></p><p class="post-abstract"><p>接下来的几篇，我们将介绍一下最流行的爬虫框架 Scrapy。本篇，我们会介绍一下 Scrapy 的基本使用。<br><img src="https://cdn.jsdelivr.net/gh/1ess/cdn/contentImg/scrapy/scrapy_architecture_02.png"></p>
<h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><hr>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre class="line-numbers language-hljs bash"><span class="hljs-comment"># scrapy startproject [文件夹名]</span><br>scrapy startproject quotetutorial<br><br><span class="hljs-comment"># 进入项目文件夹</span><br><span class="hljs-built_in">cd</span> quotetutorial<br><br><span class="hljs-comment"># scrapy genspider [项目名] [目标爬取网址]</span><br>scrapy genspider quotes quotes.toscrape.com<br><br><span class="hljs-comment"># scrapy crawl [项目名]</span><br>scrapy crawl quotes <br><br><span class="hljs-comment"><code class="language-hljs bash"><span class="hljs-comment"># scrapy startproject [文件夹名]</span><br>scrapy startproject quotetutorial<br><br><span class="hljs-comment"># 进入项目文件夹</span><br><span class="hljs-built_in">cd</span> quotetutorial<br><br><span class="hljs-comment"># scrapy genspider [项目名] [目标爬取网址]</span><br>scrapy genspider quotes quotes.toscrape.com<br><br><span class="hljs-comment"># scrapy crawl [项目名]</span><br>scrapy crawl quotes <br><br><span class="hljs-comment"># scrapy crawl [项目名] -o [保存的文件名]</span><br>scrapy crawl quotes -o quotes.json<br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>

<h2 id="Scrapy-中的-Selector"><a href="#Scrapy-中的-Selector" class="headerlink" title="Scrapy 中的 Selector"></a>Scrapy 中的 Selector</h2><hr>
<p>scrapy 的 Selector 支持两种方式提取内容: </p>
<ol>
<li>xpath()</li>
<li>css()</li>
</ol>
<p>xpath() 和 css() 的返回结果也是 Selector 对象列表，列表元素可以继续链式调用 xpath() 和 css()，获取 Selector 对象之后可以使用 get() 或 getall() 获取想要提取的内容或内容列表。<br>我个人更习惯 css() 方法: </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre class="line-numbers language-hljs python">response.css(<span class="hljs-string">&#x27;#images img::attr(src)&#x27;</span>).getall()<br><span class="hljs-comment"># [&#x27;image1_thumb.jpg&#x27;, &#x27;image2_thumb.jpg&#x27;, &#x27;image3_thumb.jpg&#x27;, &#x27;image4_thumb.jpg&#x27;, &#x27;image5_thumb.jpg&#x27;]</span><br><br>response.css(<span class="hljs-string">&#x27;a[href*=image]::attr(href)&#x27;</span>).getall()<br><span class="hljs-comment"># [&#x27;image1.html&#x27;, &#x27;image2.html&#x27;, &#x27;image3.html&#x27;, &#x27;image4.html&#x27;, &#x27;image5.html&#x27;]</span><br><br>response.css(<span class="hljs-string"><code class="language-hljs python">response.css(<span class="hljs-string">&#x27;#images img::attr(src)&#x27;</span>).getall()<br><span class="hljs-comment"># [&#x27;image1_thumb.jpg&#x27;, &#x27;image2_thumb.jpg&#x27;, &#x27;image3_thumb.jpg&#x27;, &#x27;image4_thumb.jpg&#x27;, &#x27;image5_thumb.jpg&#x27;]</span><br><br>response.css(<span class="hljs-string">&#x27;a[href*=image]::attr(href)&#x27;</span>).getall()<br><span class="hljs-comment"># [&#x27;image1.html&#x27;, &#x27;image2.html&#x27;, &#x27;image3.html&#x27;, &#x27;image4.html&#x27;, &#x27;image5.html&#x27;]</span><br><br>response.css(<span class="hljs-string">&#x27;a[href*=image] img::attr()&#x27;</span>)<br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>

<p>我们还可以使用 re() 或 re_first() 方法进行一些匹配字符串处理: </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre class="line-numbers language-hljs python">response.css(<span class="hljs-string">&#x27;a[href*=image]::text&#x27;</span>).getall()<br><span class="hljs-comment"># [&#x27;Name: My image 1 &#x27;, &#x27;Name: My image 2 &#x27;, &#x27;Name: My image 3 &#x27;, &#x27;Name: My image 4 &#x27;, &#x27;Name: My image 5 &#x27;]</span><br><br>response.css(<span class="hljs-string">&#x27;a[href*=image]::text&#x27;</span>).re(<span class="hljs-string">&#x27;Name\:(.*)&#x27;</span>)<br><span class="hljs-comment"><code class="language-hljs python">response.css(<span class="hljs-string">&#x27;a[href*=image]::text&#x27;</span>).getall()<br><span class="hljs-comment"># [&#x27;Name: My image 1 &#x27;, &#x27;Name: My image 2 &#x27;, &#x27;Name: My image 3 &#x27;, &#x27;Name: My image 4 &#x27;, &#x27;Name: My image 5 &#x27;]</span><br><br>response.css(<span class="hljs-string">&#x27;a[href*=image]::text&#x27;</span>).re(<span class="hljs-string">&#x27;Name\:(.*)&#x27;</span>)<br><span class="hljs-comment"># [&#x27; My image 1 &#x27;, &#x27; My image 2 &#x27;, &#x27; My image 3 &#x27;, &#x27; My image 4 &#x27;, &#x27; My image 5 &#x27;]</span><br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>

<p>注意: </p>
<ul>
<li>我们可以使用 response.selector 获取 Selector 对象调用 xpath() 和 css()，也可以更方便的使用 response 对象直接调用 xpath() 和 css()</li>
<li>我们可能还见过 extract() 和 extract_first()，这两个方法虽然没有被废弃，但是还是不建议使用，因为 get()和 getall()方法的输出更具可预测性</li>
</ul>
<h2 id="Scrapy-中的-Spider"><a href="#Scrapy-中的-Spider" class="headerlink" title="Scrapy 中的 Spider"></a>Scrapy 中的 Spider</h2><hr>
<p>Spider 主要用来完成爬取逻辑和网页数据的解析: </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre class="line-numbers language-hljs python"><span class="hljs-keyword">import</span> scrapy<br><span class="hljs-keyword">from</span> quotetutorial.items <span class="hljs-keyword">import</span> QuoteItem<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">QuotesSpider</span>(<span class="hljs-params">scrapy.Spider</span>):</span><br>    name = <span class="hljs-string">&#x27;quotes&#x27;</span><br>    allowed_domains = [<span class="hljs-string">&#x27;quotes.toscrape.com&#x27;</span>]<br>    start_urls = [<span class="hljs-string">&#x27;http://quotes.toscrape.com/&#x27;</span>]<br>    <span class="hljs-comment"># 覆盖 settings.py 文件</span><br>    custom_settings = &#123;<br>        <span class="hljs-string">&#x27;USER_AGENT&#x27;</span>: <span class="hljs-string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36&#x27;</span><br>    &#125;<br><br>    <span class="hljs-comment"># parse 方法为默认的回调方法，通常使用 Selector 进行数据解析并返回 Item</span><br>    <span class="hljs-comment"># 内部还可以使用 yield scrapy.Request() 方法返回多个 Request </span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span>(<span class="hljs-params">self, response</span>):</span><br>        quotes = response.css(<span class="hljs-string">&#x27;.quote&#x27;</span>)<br>        <span class="hljs-keyword">for</span> quote <span class="hljs-keyword">in</span> quotes:<br>            item = QuoteItem()<br>            text = quote.css(<span class="hljs-string">&#x27;.text::text&#x27;</span>).get()<br>            author = quote.css(<span class="hljs-string">&#x27;.author::text&#x27;</span>).get()<br>            tags = quote.css(<span class="hljs-string">&#x27;.tags .tag::text&#x27;</span>).getall()<br>            item[<span class="hljs-string">&#x27;name&#x27;</span>] = text<br>            item[<span class="hljs-string">&#x27;author&#x27;</span>] = author<br>            item[<span class="hljs-string">&#x27;tags&#x27;</span>] = tags<br>            <span class="hljs-keyword">yield</span> item<br><br>        <span class="hljs-built_in">next</span> = response.css(<span class="hljs-string">&#x27;.pager .next a::attr(href)&#x27;</span>).get()<br>        url = response.urljoin(<span class="hljs-built_in">next</span>)<br>        <span class="hljs-keyword"><code class="language-hljs python"><span class="hljs-keyword">import</span> scrapy<br><span class="hljs-keyword">from</span> quotetutorial.items <span class="hljs-keyword">import</span> QuoteItem<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">QuotesSpider</span>(<span class="hljs-params">scrapy.Spider</span>):</span><br>    name = <span class="hljs-string">&#x27;quotes&#x27;</span><br>    allowed_domains = [<span class="hljs-string">&#x27;quotes.toscrape.com&#x27;</span>]<br>    start_urls = [<span class="hljs-string">&#x27;http://quotes.toscrape.com/&#x27;</span>]<br>    <span class="hljs-comment"># 覆盖 settings.py 文件</span><br>    custom_settings = &#123;<br>        <span class="hljs-string">&#x27;USER_AGENT&#x27;</span>: <span class="hljs-string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36&#x27;</span><br>    &#125;<br><br>    <span class="hljs-comment"># parse 方法为默认的回调方法，通常使用 Selector 进行数据解析并返回 Item</span><br>    <span class="hljs-comment"># 内部还可以使用 yield scrapy.Request() 方法返回多个 Request </span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span>(<span class="hljs-params">self, response</span>):</span><br>        quotes = response.css(<span class="hljs-string">&#x27;.quote&#x27;</span>)<br>        <span class="hljs-keyword">for</span> quote <span class="hljs-keyword">in</span> quotes:<br>            item = QuoteItem()<br>            text = quote.css(<span class="hljs-string">&#x27;.text::text&#x27;</span>).get()<br>            author = quote.css(<span class="hljs-string">&#x27;.author::text&#x27;</span>).get()<br>            tags = quote.css(<span class="hljs-string">&#x27;.tags .tag::text&#x27;</span>).getall()<br>            item[<span class="hljs-string">&#x27;name&#x27;</span>] = text<br>            item[<span class="hljs-string">&#x27;author&#x27;</span>] = author<br>            item[<span class="hljs-string">&#x27;tags&#x27;</span>] = tags<br>            <span class="hljs-keyword">yield</span> item<br><br>        <span class="hljs-built_in">next</span> = response.css(<span class="hljs-string">&#x27;.pager .next a::attr(href)&#x27;</span>).get()<br>        url = response.urljoin(<span class="hljs-built_in">next</span>)<br>        <span class="hljs-keyword">yield</span> scrapy.Request(url=url, callback=self.parse)<br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>

<p>Spider 还可以接收修改其行为的参数，在命令行可以使用 -a 参数: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre class="line-numbers language-hljs bash"><code class="language-hljs bash">scrapy crawl quotes -a category=electronics<br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>

<p>在 Spider 的构造函数中可以接收该参数: </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre class="line-numbers language-hljs python"><span class="hljs-keyword">import</span> scrapy<br><span class="hljs-keyword">from</span> quotetutorial.items <span class="hljs-keyword">import</span> QuoteItem<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">QuotesSpider</span>(<span class="hljs-params">scrapy.Spider</span>):</span><br>    name = <span class="hljs-string">&#x27;quotes&#x27;</span><br>    allowed_domains = [<span class="hljs-string">&#x27;quotes.toscrape.com&#x27;</span>]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, category=<span class="hljs-literal">None</span>, *args, **kwargs</span>):</span><br>        <span class="hljs-built_in">super</span>(QuotesSpider, self).__init__(*args, **kwargs)<br>        self.start_urls = [<span class="hljs-string">f&#x27;http://quotes.toscrape.com/category=<span class="hljs-subst">&#123;category&#125;</span>&#x27;</span>]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span>(<span class="hljs-params">self, response</span>):</span><br>        <span class="hljs-keyword"><code class="language-hljs python"><span class="hljs-keyword">import</span> scrapy<br><span class="hljs-keyword">from</span> quotetutorial.items <span class="hljs-keyword">import</span> QuoteItem<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">QuotesSpider</span>(<span class="hljs-params">scrapy.Spider</span>):</span><br>    name = <span class="hljs-string">&#x27;quotes&#x27;</span><br>    allowed_domains = [<span class="hljs-string">&#x27;quotes.toscrape.com&#x27;</span>]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, category=<span class="hljs-literal">None</span>, *args, **kwargs</span>):</span><br>        <span class="hljs-built_in">super</span>(QuotesSpider, self).__init__(*args, **kwargs)<br>        self.start_urls = [<span class="hljs-string">f&#x27;http://quotes.toscrape.com/category=<span class="hljs-subst">&#123;category&#125;</span>&#x27;</span>]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span>(<span class="hljs-params">self, response</span>):</span><br>        <span class="hljs-keyword">pass</span><br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>

<h2 id="Scrapy-中的-Item"><a href="#Scrapy-中的-Item" class="headerlink" title="Scrapy 中的 Item"></a>Scrapy 中的 Item</h2><hr>
<p>为了定义通用输出数据格式，Scrapy 提供了 Item 类。它们提供类似字典的 API，并具有用于声明其可用字段的方便语法: </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre class="line-numbers language-hljs python"><span class="hljs-keyword">import</span> scrapy<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">QuoteItem</span>(<span class="hljs-params">scrapy.Item</span>):</span><br>    <span class="hljs-comment"><code class="language-hljs python"><span class="hljs-keyword">import</span> scrapy<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">QuoteItem</span>(<span class="hljs-params">scrapy.Item</span>):</span><br>    <span class="hljs-comment"># define the fields for your item here like:</span><br>    name = scrapy.Field()<br>    author = scrapy.Field()<br>    tags = scrapy.Field()<br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>

<h2 id="Scrapy-中的-Pipelinie"><a href="#Scrapy-中的-Pipelinie" class="headerlink" title="Scrapy 中的 Pipelinie"></a>Scrapy 中的 Pipelinie</h2><hr>
<p>Pipeline 可以对抓取下来的 Item 进行进一步处理: </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre class="line-numbers language-hljs python"><span class="hljs-keyword">import</span> pymongo<br><span class="hljs-keyword">from</span> scrapy.exceptions <span class="hljs-keyword">import</span> DropItem<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TextPipeline</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        self.limit = <span class="hljs-number">50</span><br><br>    <span class="hljs-comment"># process_item 返回 item 或 DropItem 对象</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span>(<span class="hljs-params">self, item, spider</span>):</span><br>        <span class="hljs-keyword">if</span> item[<span class="hljs-string">&#x27;name&#x27;</span>]:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(item[<span class="hljs-string">&#x27;name&#x27;</span>]) &gt; self.limit:<br>                item[<span class="hljs-string">&#x27;name&#x27;</span>] = item[<span class="hljs-string">&#x27;name&#x27;</span>][<span class="hljs-number">0</span>:self.limit] + <span class="hljs-string">&#x27;...&#x27;</span><br>            <span class="hljs-keyword">return</span> item<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> DropItem(<span class="hljs-string">&#x27;Missing Text&#x27;</span>)<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MongoPipeline</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, mongo_uri, mongo_db</span>):</span><br>        self.mongo_uri = mongo_uri<br>        self.mongo_db = mongo_db<br><br><span class="hljs-meta">    @classmethod</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">from_crawler</span>(<span class="hljs-params">cls, crawler</span>):</span><br>        <span class="hljs-keyword">return</span> cls(<br>            mongo_db = crawler.settings.get(<span class="hljs-string">&#x27;MONGO_DB&#x27;</span>),<br>            mongo_uri = crawler.settings.get(<span class="hljs-string">&#x27;MONGO_URI&#x27;</span>)<br>        )<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">open_spider</span>(<span class="hljs-params">self, spider</span>):</span><br>        self.client = pymongo.MongoClient(self.mongo_uri)<br>        self.db = self.client[self.mongo_db]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">close_spider</span>(<span class="hljs-params">self, spider</span>):</span><br>        self.client.close()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span>(<span class="hljs-params">self, item, spider</span>):</span><br>        name = item.__class__.__name__<br>        self.db[name].insert(<span class="hljs-built_in">dict</span>(item))<br>        <span class="hljs-keyword"><code class="language-hljs python"><span class="hljs-keyword">import</span> pymongo<br><span class="hljs-keyword">from</span> scrapy.exceptions <span class="hljs-keyword">import</span> DropItem<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TextPipeline</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        self.limit = <span class="hljs-number">50</span><br><br>    <span class="hljs-comment"># process_item 返回 item 或 DropItem 对象</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span>(<span class="hljs-params">self, item, spider</span>):</span><br>        <span class="hljs-keyword">if</span> item[<span class="hljs-string">&#x27;name&#x27;</span>]:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(item[<span class="hljs-string">&#x27;name&#x27;</span>]) &gt; self.limit:<br>                item[<span class="hljs-string">&#x27;name&#x27;</span>] = item[<span class="hljs-string">&#x27;name&#x27;</span>][<span class="hljs-number">0</span>:self.limit] + <span class="hljs-string">&#x27;...&#x27;</span><br>            <span class="hljs-keyword">return</span> item<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> DropItem(<span class="hljs-string">&#x27;Missing Text&#x27;</span>)<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MongoPipeline</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, mongo_uri, mongo_db</span>):</span><br>        self.mongo_uri = mongo_uri<br>        self.mongo_db = mongo_db<br><br><span class="hljs-meta">    @classmethod</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">from_crawler</span>(<span class="hljs-params">cls, crawler</span>):</span><br>        <span class="hljs-keyword">return</span> cls(<br>            mongo_db = crawler.settings.get(<span class="hljs-string">&#x27;MONGO_DB&#x27;</span>),<br>            mongo_uri = crawler.settings.get(<span class="hljs-string">&#x27;MONGO_URI&#x27;</span>)<br>        )<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">open_spider</span>(<span class="hljs-params">self, spider</span>):</span><br>        self.client = pymongo.MongoClient(self.mongo_uri)<br>        self.db = self.client[self.mongo_db]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">close_spider</span>(<span class="hljs-params">self, spider</span>):</span><br>        self.client.close()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span>(<span class="hljs-params">self, item, spider</span>):</span><br>        name = item.__class__.__name__<br>        self.db[name].insert(<span class="hljs-built_in">dict</span>(item))<br>        <span class="hljs-keyword">return</span> item<br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>

<h2 id="Scrapy-中的-Settings"><a href="#Scrapy-中的-Settings" class="headerlink" title="Scrapy 中的 Settings"></a>Scrapy 中的 Settings</h2><hr>
<p>settings.py 为 Scrapy 中的配置文件，进行项目的配置工作: </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre class="line-numbers language-hljs python"><span class="hljs-comment"># Obey robots.txt rules</span><br>ROBOTSTXT_OBEY = <span class="hljs-literal">True</span><br><br><span class="hljs-comment"># 配置变量</span><br>MONGO_DB = <span class="hljs-string">&#x27;quotetutorial&#x27;</span><br>MONGO_URI = <span class="hljs-string">&#x27;localhost&#x27;</span><br><br><span class="hljs-comment"># user-agent</span><br>USER_AGENT: <span class="hljs-string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36&#x27;</span><br><br><span class="hljs-comment"># Override the default request headers</span><br>DEFAULT_REQUEST_HEADERS = &#123;<br>  <span class="hljs-string">&#x27;Accept&#x27;</span>: <span class="hljs-string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;</span>,<br>  <span class="hljs-string">&#x27;Accept-Language&#x27;</span>: <span class="hljs-string">&#x27;en&#x27;</span><br>&#125;<br><br><span class="hljs-comment"># Configure item pipelines</span><br><span class="hljs-comment"># 管道优先级范围 0 - 1000，数字越小，优先级越高</span><br>ITEM_PIPELINES = &#123;<br>   <span class="hljs-string">&#x27;quotetutorial.pipelines.TextPipeline&#x27;</span>: <span class="hljs-number">300</span>,<br>   <span class="hljs-string">&#x27;quotetutorial.pipelines.MongoPipeline&#x27;</span>: <span class="hljs-number">400</span><br>&#125;<br><br><span class="hljs-comment"># Enable or disable downloader middlewares</span><br><span class="hljs-comment"># 可以在这个配置中关闭不需要的默认中间件</span><br>DOWNLOADER_MIDDLEWARES = &#123;<br>    <span class="hljs-string">&#x27;httpbintest.middlewares.ProxyMiddleware&#x27;</span>: <span class="hljs-number">100</span>,<br>    <span class="hljs-string">&#x27;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#x27;</span>: <span class="hljs-literal">None</span>,<br>    <span class="hljs-string">&#x27;scrapy.downloadermiddlewares.retry.RetryMiddleware&#x27;</span>: <span class="hljs-literal"><code class="language-hljs python"><span class="hljs-comment"># Obey robots.txt rules</span><br>ROBOTSTXT_OBEY = <span class="hljs-literal">True</span><br><br><span class="hljs-comment"># 配置变量</span><br>MONGO_DB = <span class="hljs-string">&#x27;quotetutorial&#x27;</span><br>MONGO_URI = <span class="hljs-string">&#x27;localhost&#x27;</span><br><br><span class="hljs-comment"># user-agent</span><br>USER_AGENT: <span class="hljs-string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36&#x27;</span><br><br><span class="hljs-comment"># Override the default request headers</span><br>DEFAULT_REQUEST_HEADERS = &#123;<br>  <span class="hljs-string">&#x27;Accept&#x27;</span>: <span class="hljs-string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;</span>,<br>  <span class="hljs-string">&#x27;Accept-Language&#x27;</span>: <span class="hljs-string">&#x27;en&#x27;</span><br>&#125;<br><br><span class="hljs-comment"># Configure item pipelines</span><br><span class="hljs-comment"># 管道优先级范围 0 - 1000，数字越小，优先级越高</span><br>ITEM_PIPELINES = &#123;<br>   <span class="hljs-string">&#x27;quotetutorial.pipelines.TextPipeline&#x27;</span>: <span class="hljs-number">300</span>,<br>   <span class="hljs-string">&#x27;quotetutorial.pipelines.MongoPipeline&#x27;</span>: <span class="hljs-number">400</span><br>&#125;<br><br><span class="hljs-comment"># Enable or disable downloader middlewares</span><br><span class="hljs-comment"># 可以在这个配置中关闭不需要的默认中间件</span><br>DOWNLOADER_MIDDLEWARES = &#123;<br>    <span class="hljs-string">&#x27;httpbintest.middlewares.ProxyMiddleware&#x27;</span>: <span class="hljs-number">100</span>,<br>    <span class="hljs-string">&#x27;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#x27;</span>: <span class="hljs-literal">None</span>,<br>    <span class="hljs-string">&#x27;scrapy.downloadermiddlewares.retry.RetryMiddleware&#x27;</span>: <span class="hljs-literal">None</span><br>&#125;<br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>

<h2 id="Scrapy-中的-Downloader-Middleware"><a href="#Scrapy-中的-Downloader-Middleware" class="headerlink" title="Scrapy 中的 Downloader Middleware"></a>Scrapy 中的 Downloader Middleware</h2><hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre class="line-numbers language-hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ProxyMiddleware</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br><br>    <span class="hljs-comment"># Called for each request that goes through the downloader</span><br>    <span class="hljs-comment"># middleware.</span><br><br>    <span class="hljs-comment"># Must either:</span><br>    <span class="hljs-comment"># - return None: continue processing this request</span><br>    <span class="hljs-comment"># - or return a Response object</span><br>    <span class="hljs-comment"># - or return a Request object</span><br>    <span class="hljs-comment"># - or raise IgnoreRequest: process_exception() methods of</span><br>    <span class="hljs-comment">#   installed downloader middleware will be called</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_request</span>(<span class="hljs-params">self, request, spider</span>):</span><br>        spider.logger.info(<span class="hljs-string">&#x27;Using Proxy&#x27;</span>)<br>        request.meta[<span class="hljs-string">&#x27;proxy&#x27;</span>] = <span class="hljs-string">&#x27;https://46.10.240.182:55878&#x27;</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br><br><br>    <span class="hljs-comment"># Called with the response returned from the downloader.</span><br><br>    <span class="hljs-comment"># Must either;</span><br>    <span class="hljs-comment"># - return a Response object</span><br>    <span class="hljs-comment"># - return a Request object</span><br>    <span class="hljs-comment"># - or raise IgnoreRequest</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_response</span>(<span class="hljs-params">self, request, response, spider</span>):</span><br>        response.status = <span class="hljs-number">201</span><br>        <span class="hljs-keyword">return</span> response<br><br>    <span class="hljs-comment"># Called when a download handler or a process_request()</span><br>    <span class="hljs-comment"># (from other downloader middleware) raises an exception.</span><br><br>    <span class="hljs-comment"># Must either:</span><br>    <span class="hljs-comment"># - return None: continue processing this exception</span><br>    <span class="hljs-comment"># - return a Response object: stops process_exception() chain</span><br>    <span class="hljs-comment"># - return a Request object: stops process_exception() chain</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_exception</span>(<span class="hljs-params">self, request, exception, spider</span>):</span><br>        spider.logger.debug(<span class="hljs-string">&#x27;Get Exception&#x27;</span>)<br>        <span class="hljs-keyword"><code class="language-hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ProxyMiddleware</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br><br>    <span class="hljs-comment"># Called for each request that goes through the downloader</span><br>    <span class="hljs-comment"># middleware.</span><br><br>    <span class="hljs-comment"># Must either:</span><br>    <span class="hljs-comment"># - return None: continue processing this request</span><br>    <span class="hljs-comment"># - or return a Response object</span><br>    <span class="hljs-comment"># - or return a Request object</span><br>    <span class="hljs-comment"># - or raise IgnoreRequest: process_exception() methods of</span><br>    <span class="hljs-comment">#   installed downloader middleware will be called</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_request</span>(<span class="hljs-params">self, request, spider</span>):</span><br>        spider.logger.info(<span class="hljs-string">&#x27;Using Proxy&#x27;</span>)<br>        request.meta[<span class="hljs-string">&#x27;proxy&#x27;</span>] = <span class="hljs-string">&#x27;https://46.10.240.182:55878&#x27;</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br><br><br>    <span class="hljs-comment"># Called with the response returned from the downloader.</span><br><br>    <span class="hljs-comment"># Must either;</span><br>    <span class="hljs-comment"># - return a Response object</span><br>    <span class="hljs-comment"># - return a Request object</span><br>    <span class="hljs-comment"># - or raise IgnoreRequest</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_response</span>(<span class="hljs-params">self, request, response, spider</span>):</span><br>        response.status = <span class="hljs-number">201</span><br>        <span class="hljs-keyword">return</span> response<br><br>    <span class="hljs-comment"># Called when a download handler or a process_request()</span><br>    <span class="hljs-comment"># (from other downloader middleware) raises an exception.</span><br><br>    <span class="hljs-comment"># Must either:</span><br>    <span class="hljs-comment"># - return None: continue processing this exception</span><br>    <span class="hljs-comment"># - return a Response object: stops process_exception() chain</span><br>    <span class="hljs-comment"># - return a Request object: stops process_exception() chain</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_exception</span>(<span class="hljs-params">self, request, exception, spider</span>):</span><br>        spider.logger.debug(<span class="hljs-string">&#x27;Get Exception&#x27;</span>)<br>        <span class="hljs-keyword">return</span> request<br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure></p></div><div class="pagination"><p class="clearfix"><span class="pre pagbuttons"><a role="navigation" href="/Python(%E5%8D%81%E4%BA%94)/" title=""><i class="fa fa-angle-double-left"></i>&nbsp;上一篇: </a></span><span>&nbsp;</span><span class="next pagbuttons"><a role="navigation" href="/Linux(%E4%B8%80)/" title="">下一篇: &nbsp;<i class="fa fa-angle-double-right"></i></a></span></p></div></div></div></div><div class="visible-xs site-bottom-footer"><footer><p>&copy;&nbsp;2021&nbsp;</p><p>如果五分钟后她必须进安检，如果安检在十米之外</p><p>那意味着，你们可以亲吻四分五十秒。&nbsp;</p></footer></div></div></div></div><script src="/js/jquery-3.1.0.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/google-analytics.js"></script><script src="/js/typography.js"></script></body></html>